![image](https://github.com/user-attachments/assets/c460524f-aeda-4755-ae94-ed5c43898ce0)layout: post
author: Xu ShengChee
title: "Applied Data Science Project Documentation"
categories: ITD214
---
## Project Background
Investing in movie and television production requires significant **financial resources** and **coordination of a large workforce**. Nonetheless, the reality is that **not every project turns out to be commercially successful or profitable**. 

Our team plans to use machine learning to **identify audience preferences and trends**. If this approach works, it could help **reduce the risk of production failures**. With the abundance of available data, we aim to demonstrate how making decisions based on consumer preferences can **enhance the likelihood of success**.

### Business Goal:
To be able to **sustainably identify popular topics** among audiences and **predict the success of prospective films**. 

### Objectives:
1. Train a **text classification model** to predict the sentiment of a movie review, to automate the labelling of the sentiment for new movie reviews on IMDB.
2. Perform **topic modelling** on the movie reviews to uncover insights on the **topics prevalent in positive reviews and likewise for negative reviews**.
3. Train a **binary classification model** to predict **if a prospective films would be well be rated**.
4. Train a **regression model** to predict prospective films’ IMDB votes and hence its potential **audience engagement level**.

![image](https://github.com/user-attachments/assets/bb4af838-f8b3-4c83-9213-b5e146b1be98)


### Success Criteria:
- To automate the classification of new movie reviews with a 80% accuracy
- To identify at least 2 topics that are associated with positive sentiment
- Predict for a prospective film, at 60% accuracy rate or a normalised RMSE of 0.2 for its IMDB score and IMDB number of votes

## Work Accomplished
The repository outlines the effort made towards Business Objective #3: 3. Train a **binary classification model** to predict **if a prospective films would be well be rated**.

The goal is to automate the process of predicting if a particular new movie would be well rated by IMDB.

The work accomplished for the other business objectives are detailed in the following sites:

[Business Objective #1](https://kokjian.github.io/itd214/2024/08/01/applied-data-science-project.html)

[Business Objective #2](https://siewlw.github.io/itd214/2024/08/01/applied-data-science-project.html)

[Business Objective #4](https://jianweigoh.github.io/itd214/2024/08/01/applied-data-science-project.html)

### Data Understanding
The dataset comprises 5,806 individual records of Netflix movies and shows, with each record represented by 11 distinct data fields. The information is sourced from IMDB and is organized in a tabular format.

### Exploratory Data Analysis (EDA)

1. Dataset visualised via basic panda head and info method

![image](https://github.com/user-attachments/assets/dc8c46be-7747-475e-b47b-454f4ed139e3)

2. Secondly, an EDA table function (modified from [https://www.kaggle.com/code/keishibata/netflix-movies-and-shows-eda-wordcloud](https://www.kaggle.com/code/keishibata/netflix-movies-and-shows-eda-wordcloud)) was utilized to analyze the dataset, focusing on the count of missing values, the number of unique values, and the statistics generated by the pandas describe method for each feature.

Code:

![image](https://github.com/user-attachments/assets/bc05dfcc-d657-44b0-941d-3161e5747a87)

Visualiation:

![image](https://github.com/user-attachments/assets/7133ca58-7ce0-444b-afaf-b838d770f6ec)

3. EDA using ydata-profiling was employed to quickly generate histogram visualizations of the available features and to uncover any insights that might have been overlooked in the initial exploratory data analysis steps.

![image](https://github.com/user-attachments/assets/30a38fd0-bb5f-4385-bd4a-acc9651b8dd9)
![image](https://github.com/user-attachments/assets/2fc97ad3-6145-474a-ba5a-f73fd40009de)


4. Finally, supplementary visualizations were created to complement the histograms produced by ydata-profiling and to provide a more detailed exploration of the input and target (imbd score) variables.

![image](https://github.com/user-attachments/assets/e435cd9b-130e-444d-900e-688a9615134c)
![image](https://github.com/user-attachments/assets/47200b64-1e73-4d07-b37c-6ede03336947)

5. Addition visualizations were done for features such as year of release, runtime of movies/shows. Country of production ranked based on number of movies/shows produced

![image](https://github.com/user-attachments/assets/708070eb-d2b7-4204-ae1e-6d4cba9a36a3)


### Data Preparation

Duplicate entries were removed based on both the title AND the release year. This approach addresses the common occurrence of remakes sharing the same title, ensuring that each instance is treated as a distinct record during modeling. Additionally, records with missing values in the target variable were removed.

![image](https://github.com/user-attachments/assets/1601e204-b80d-4f98-b7fb-bb09898aab4c)


Subsequently, we remove entries that do not make logical sense
•	Records without target variable
•	Records with runtime that is = 0

![image](https://github.com/user-attachments/assets/f10aa118-82c5-4337-bb4b-8fd346448ca7)


The dataset includes information on both movies and television shows. While movies typically have a shorter runtime, shows may be broadcast over multiple seasons or episodes. Therefore, it is proposed to combine runtime and seasons into a single feature, 'runtime_combined', to more accurately represent the total duration of each title.

![image](https://github.com/user-attachments/assets/555c68fc-8779-4fbe-b0b8-985299c16b00)


One hot encoding was also performed on categorical features
•	Type (Movie vs Show)
•	Genres
•	Production country
•	Content rating
•	Year of movie release

![image](https://github.com/user-attachments/assets/c137f6c3-0c0b-42a9-83dc-dd3ede66fa84)

Additional Feature engineering
•	The first production country listed was mapped to its corresponding continent to simplify the number of dimensions, while other production countries were excluded.
•	Content ratings were grouped into bins to consolidate similar age bands and reduce dimensionality.
•	The year of movie release was binned into three equal-sized intervals.
•	Features not intended for modeling were removed at this stage.

![image](https://github.com/user-attachments/assets/592ad03c-b919-493b-b0b5-9f36458ff7ef)
![image](https://github.com/user-attachments/assets/2b7ad601-a617-452c-bc1b-b895eeec356c)


## Modelling

Prior to modelling, feature engineering step specific to objective 3 were executed:
• Converted IMDB score valeus into data by creating a new column "worth_watching?". Movies and shows with IMDB score greater or equal to 7 were labelled as “worth_watching” while <7 as “waste of time”.
 
![image](https://github.com/user-attachments/assets/273bd3f2-cbba-4b1a-920b-b47966eebfc1)


#### Inputs and output variables 

To predict whether an IMDb movie is worth watching, input variables such as runtime, genre, maturity rating, year of release, and country of production were fed into the models.

![image](https://github.com/user-attachments/assets/c0072054-904c-4db6-b060-987d5bdc891b)


#### Models used in testing

![image](https://github.com/user-attachments/assets/993d2c6d-43b9-46a9-bcce-0d4504c6fd01)

#### Multicolinarity check

Before initiating the modeling process, a multicollinearity check was performed on the dataset to ensure that no two or more predictor variables in the model were highly correlated. High correlations can make it difficult to determine the individual effect of each predictor.

![image](https://github.com/user-attachments/assets/36647b4a-7ff8-47c9-a425-4b04fced14ac)

The correlation matrix did not indicate any issues with multicollinearity.

### Modelling - Results of binary classification model

The five models were compared based on their performance metrics, including accuracy, precision, and recall scores. Each model was ranked according to its accuracy score. Among the five models, Random Forest emerged as the most accurate in predicting whether a movie is "worth watching."


| Model                 | Accuracy | Precision | Recall |
|-----------------------|----------|-----------|--------|
| Random Forest         | 0.70417  | 0.651961  | 0.532  |
| Support Vector Machine| 0.691581 | 0.647541  | 0.474  |
| Logistic Regression   | 0.690795 | 0.633416  | 0.508  |
| Neural Network        | 0.685287 | 0.585616  | 0.684  |
| Decision Tree         | 0.661684 | 0.572917  | 0.55   |

The following are the features of the model:

![image](https://github.com/user-attachments/assets/75068552-38e2-4cfe-8cf7-dcc56cc5af64)

To identify the important features contributing to our model, I filtered out those with a weight above 0.02.

![image](https://github.com/user-attachments/assets/528a2600-7c45-48be-83e4-e241a2691933)


## Recommendation and Analysis

The models performed reasonably well, with accuracies ranging from 0.66 to 0.70. Among them, the Random Forest model yielded the most accurate results. Precision varied from 0.57 to 0.65, while recall ranged from 0.44 to 0.55. The Neural Network achieved the highest precision (0.692), and the Decision Tree had the highest recall (0.446). 

Overall, the Random Forest model provides the most balanced results in terms of accuracy, precision, and recall.

By analyzing the Random Forest model, we found that movie runtime and whether the show is a movie or not are the most significant factors influencing the outcome. Among the genres, 'documentary,' 'drama,' and 'comedy' contribute more to the outcome. Maturity rating, year of release, and country of production do not appear to significantly affect the outcome.


#### Areas for improvement
Based on logical reasoning and cultural understanding, the IMDb dataset we used does not include information on the budget of shows or details about the directors, actors, and actresses involved. Additionally, different movies may perform variably across countries due to differing cultural contexts.

There are several areas for potential investigation to enhance the analysis:
•	Seasonality of Release Dates: Investigate how the time of year when shows are released may affect their performance.
•	Geopolitical Climate: Consider the impact of geopolitical events on movie performance.
•	Seasonal Variations: Examine how different seasons of the year might influence viewer preferences and movie success.



## AI Ethics

The dataset did not contain any personal or confidential information. While the model's inability to accurately predict the success of a movie or show is unlikely to cause societal harm, it could impact the production company financially. Therefore, it is recommended that a human-in-the-loop approach be considered when using this classification model. This approach is not necessarily about safety but rather acknowledges that certain aspects of film and show creation cannot be fully addressed by machine learning alone. Additional insights from other sources are needed for more informed and strategic decision-making. The model should be used to support decision-making processes rather than to replace human judgment and draw conclusions independently.

![image](https://github.com/user-attachments/assets/d21e68d2-611c-4c06-95e2-4edae1afe9a1)




## Source Codes and Datasets
https://github.com/xushengchee/ITD214
